{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab743fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d06360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe3e2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>286.0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>31.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>78.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>34.5</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>193.7</td>\n",
       "      <td>35.4</td>\n",
       "      <td>75.6</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>199.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper  sales\n",
       "188  286.0   13.9        3.7   15.9\n",
       "66    31.5   24.6        2.2    9.5\n",
       "114   78.2   46.8       34.5   14.6\n",
       "141  193.7   35.4       75.6   19.2\n",
       "50   199.8    3.1       34.6   11.4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323b6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df.drop('sales',axis = 1)\n",
    "y =df['sales']\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9229556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476623aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78551f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e48c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24808a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5460ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elastic_net_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa2d8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0,1,1,5,10,50,100],\n",
    "              'l1_ratio':[.1,.5,.7,.95,.99,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c443317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97eb9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(estimator=base_elastic_net_model,\n",
    "                         param_grid=param_grid,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1027e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 2.817e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+02, tolerance: 3.053e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+02, tolerance: 2.831e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e+02, tolerance: 2.905e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+02, tolerance: 3.095e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   2.3s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=0, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=0, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=0, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 3.684e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0, 1, 1, 5, 10, 50, 100],\n",
       "                         &#x27;l1_ratio&#x27;: [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0, 1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cfe4e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0, l1_ratio=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0, l1_ratio=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet(alpha=0, l1_ratio=0.1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28df315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0, 'l1_ratio': 0.1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c429238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483565</td>\n",
       "      <td>9.601356e-01</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>3.273974e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.1}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002999</td>\n",
       "      <td>8.341244e-07</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.805696e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.5}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002797</td>\n",
       "      <td>4.021432e-04</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>4.001866e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.7}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003061</td>\n",
       "      <td>1.242442e-04</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.899403e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.95}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002798</td>\n",
       "      <td>3.988050e-04</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>2.303671e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 0.99}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003196</td>\n",
       "      <td>4.015004e-04</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>3.905483e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'l1_ratio': 1}</td>\n",
       "      <td>-3.139328</td>\n",
       "      <td>-1.622463</td>\n",
       "      <td>-5.373837</td>\n",
       "      <td>-2.242246</td>\n",
       "      <td>-4.341671</td>\n",
       "      <td>-3.343909</td>\n",
       "      <td>1.366384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.900378e-04</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.998281e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-9.827475</td>\n",
       "      <td>-5.261525</td>\n",
       "      <td>-11.875347</td>\n",
       "      <td>-7.449195</td>\n",
       "      <td>-8.542329</td>\n",
       "      <td>-8.591174</td>\n",
       "      <td>2.222939</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001601</td>\n",
       "      <td>4.911723e-04</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.899792e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-8.707071</td>\n",
       "      <td>-4.214228</td>\n",
       "      <td>-10.879261</td>\n",
       "      <td>-6.204545</td>\n",
       "      <td>-7.173031</td>\n",
       "      <td>-7.435627</td>\n",
       "      <td>2.255532</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>4.298417e-06</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>4.000168e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-7.920870</td>\n",
       "      <td>-3.549562</td>\n",
       "      <td>-10.024877</td>\n",
       "      <td>-5.379553</td>\n",
       "      <td>-6.324836</td>\n",
       "      <td>-6.639940</td>\n",
       "      <td>2.206213</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001801</td>\n",
       "      <td>4.001552e-04</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>2.733404e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-6.729435</td>\n",
       "      <td>-2.591285</td>\n",
       "      <td>-8.709842</td>\n",
       "      <td>-4.156317</td>\n",
       "      <td>-5.329916</td>\n",
       "      <td>-5.503359</td>\n",
       "      <td>2.102835</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002395</td>\n",
       "      <td>1.379934e-03</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>1.780040e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-6.521344</td>\n",
       "      <td>-2.431385</td>\n",
       "      <td>-8.471086</td>\n",
       "      <td>-3.946327</td>\n",
       "      <td>-5.151344</td>\n",
       "      <td>-5.304297</td>\n",
       "      <td>2.079945</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001762</td>\n",
       "      <td>6.841471e-04</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>3.957563e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 1}</td>\n",
       "      <td>-6.468807</td>\n",
       "      <td>-2.391483</td>\n",
       "      <td>-8.410171</td>\n",
       "      <td>-3.893566</td>\n",
       "      <td>-5.105922</td>\n",
       "      <td>-5.253990</td>\n",
       "      <td>2.073832</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001602</td>\n",
       "      <td>4.875400e-04</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.901746e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-9.827475</td>\n",
       "      <td>-5.261525</td>\n",
       "      <td>-11.875347</td>\n",
       "      <td>-7.449195</td>\n",
       "      <td>-8.542329</td>\n",
       "      <td>-8.591174</td>\n",
       "      <td>2.222939</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001353</td>\n",
       "      <td>5.220332e-04</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>4.327292e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-8.707071</td>\n",
       "      <td>-4.214228</td>\n",
       "      <td>-10.879261</td>\n",
       "      <td>-6.204545</td>\n",
       "      <td>-7.173031</td>\n",
       "      <td>-7.435627</td>\n",
       "      <td>2.255532</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001218</td>\n",
       "      <td>3.927092e-04</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>5.012460e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-7.920870</td>\n",
       "      <td>-3.549562</td>\n",
       "      <td>-10.024877</td>\n",
       "      <td>-5.379553</td>\n",
       "      <td>-6.324836</td>\n",
       "      <td>-6.639940</td>\n",
       "      <td>2.206213</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001842</td>\n",
       "      <td>7.131130e-04</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>3.922075e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-6.729435</td>\n",
       "      <td>-2.591285</td>\n",
       "      <td>-8.709842</td>\n",
       "      <td>-4.156317</td>\n",
       "      <td>-5.329916</td>\n",
       "      <td>-5.503359</td>\n",
       "      <td>2.102835</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001071</td>\n",
       "      <td>5.248376e-04</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>4.910559e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-6.521344</td>\n",
       "      <td>-2.431385</td>\n",
       "      <td>-8.471086</td>\n",
       "      <td>-3.946327</td>\n",
       "      <td>-5.151344</td>\n",
       "      <td>-5.304297</td>\n",
       "      <td>2.079945</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.891933e-04</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>4.905644e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 1}</td>\n",
       "      <td>-6.468807</td>\n",
       "      <td>-2.391483</td>\n",
       "      <td>-8.410171</td>\n",
       "      <td>-3.893566</td>\n",
       "      <td>-5.105922</td>\n",
       "      <td>-5.253990</td>\n",
       "      <td>2.073832</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>8.740569e-07</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>4.917984e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.1}</td>\n",
       "      <td>-22.979265</td>\n",
       "      <td>-15.547104</td>\n",
       "      <td>-23.668249</td>\n",
       "      <td>-19.921063</td>\n",
       "      <td>-16.262737</td>\n",
       "      <td>-19.675684</td>\n",
       "      <td>3.334901</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>6.503192e-07</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>8.003731e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.5}</td>\n",
       "      <td>-27.793488</td>\n",
       "      <td>-18.602269</td>\n",
       "      <td>-27.107849</td>\n",
       "      <td>-23.945227</td>\n",
       "      <td>-18.064635</td>\n",
       "      <td>-23.102694</td>\n",
       "      <td>4.108297</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.435272e-06</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>5.091228e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.7}</td>\n",
       "      <td>-29.655510</td>\n",
       "      <td>-21.085059</td>\n",
       "      <td>-29.629478</td>\n",
       "      <td>-26.724595</td>\n",
       "      <td>-20.223654</td>\n",
       "      <td>-25.463659</td>\n",
       "      <td>4.077877</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>4.004002e-04</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>3.992662e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.895315e-04</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.895122e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>7.480484e-04</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>7.859155e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>5.687055e-04</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>5.454266e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.1}</td>\n",
       "      <td>-27.385346</td>\n",
       "      <td>-19.159534</td>\n",
       "      <td>-27.635464</td>\n",
       "      <td>-24.154104</td>\n",
       "      <td>-18.968161</td>\n",
       "      <td>-23.460522</td>\n",
       "      <td>3.794608</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001589</td>\n",
       "      <td>4.960133e-04</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>5.006172e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002189</td>\n",
       "      <td>3.690924e-04</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.000664e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.896291e-04</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.999711e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001271</td>\n",
       "      <td>4.146482e-04</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>8.637223e-05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001534</td>\n",
       "      <td>6.010263e-04</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>4.102187e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001597</td>\n",
       "      <td>4.701403e-04</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>4.586989e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001091</td>\n",
       "      <td>1.867331e-04</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>4.122232e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001218</td>\n",
       "      <td>3.901200e-04</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>3.994744e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000881</td>\n",
       "      <td>2.631107e-04</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>3.678495e-05</td>\n",
       "      <td>50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001401</td>\n",
       "      <td>4.522682e-04</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>4.930919e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>4.078729e-04</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>3.996154e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001284</td>\n",
       "      <td>7.435320e-04</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>4.281427e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001005</td>\n",
       "      <td>6.301315e-04</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>2.050154e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>7.979012e-07</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>5.519789e-07</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.001199</td>\n",
       "      <td>3.997333e-04</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>4.004482e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001002</td>\n",
       "      <td>2.533976e-06</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.422006e-07</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.889866e-04</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>8.064048e-07</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.483565  9.601356e-01         0.001165    3.273974e-04           0   \n",
       "1        0.002999  8.341244e-07         0.001001    1.805696e-06           0   \n",
       "2        0.002797  4.021432e-04         0.000800    4.001866e-04           0   \n",
       "3        0.003061  1.242442e-04         0.000600    4.899403e-04           0   \n",
       "4        0.002798  3.988050e-04         0.001001    2.303671e-06           0   \n",
       "5        0.003196  4.015004e-04         0.000730    3.905483e-04           0   \n",
       "6        0.001600  4.900378e-04         0.000800    3.998281e-04           1   \n",
       "7        0.001601  4.911723e-04         0.000400    4.899792e-04           1   \n",
       "8        0.001999  4.298417e-06         0.000800    4.000168e-04           1   \n",
       "9        0.001801  4.001552e-04         0.000998    2.733404e-06           1   \n",
       "10       0.002395  1.379934e-03         0.001008    1.780040e-05           1   \n",
       "11       0.001762  6.841471e-04         0.000691    3.957563e-04           1   \n",
       "12       0.001602  4.875400e-04         0.000600    4.901746e-04           1   \n",
       "13       0.001353  5.220332e-04         0.000491    4.327292e-04           1   \n",
       "14       0.001218  3.927092e-04         0.000613    5.012460e-04           1   \n",
       "15       0.001842  7.131130e-04         0.001213    3.922075e-04           1   \n",
       "16       0.001071  5.248376e-04         0.000601    4.910559e-04           1   \n",
       "17       0.001400  4.891933e-04         0.000601    4.905644e-04           1   \n",
       "18       0.002000  8.740569e-07         0.000402    4.917984e-04           5   \n",
       "19       0.001000  6.503192e-07         0.001041    8.003731e-05           5   \n",
       "20       0.001000  1.435272e-06         0.001001    5.091228e-07           5   \n",
       "21       0.001200  4.004002e-04         0.000799    3.992662e-04           5   \n",
       "22       0.001400  4.895315e-04         0.000400    4.895122e-04           5   \n",
       "23       0.000800  7.480484e-04         0.000602    7.859155e-04           5   \n",
       "24       0.001326  5.687055e-04         0.000657    5.454266e-04          10   \n",
       "25       0.001589  4.960133e-04         0.000613    5.006172e-04          10   \n",
       "26       0.002189  3.690924e-04         0.000200    4.000664e-04          10   \n",
       "27       0.001600  4.896291e-04         0.000800    3.999711e-04          10   \n",
       "28       0.001271  4.146482e-04         0.000937    8.637223e-05          10   \n",
       "29       0.001534  6.010263e-04         0.000817    4.102187e-04          10   \n",
       "30       0.001597  4.701403e-04         0.000421    4.586989e-04          50   \n",
       "31       0.001091  1.867331e-04         0.000821    4.122232e-04          50   \n",
       "32       0.001218  3.901200e-04         0.000799    3.994744e-04          50   \n",
       "33       0.000881  2.631107e-04         0.001021    3.678495e-05          50   \n",
       "34       0.001401  4.522682e-04         0.000403    4.930919e-04          50   \n",
       "35       0.001187  4.078729e-04         0.000799    3.996154e-04          50   \n",
       "36       0.001284  7.435320e-04         0.000290    4.281427e-04         100   \n",
       "37       0.001005  6.301315e-04         0.001083    2.050154e-04         100   \n",
       "38       0.001001  7.979012e-07         0.001000    5.519789e-07         100   \n",
       "39       0.001199  3.997333e-04         0.000801    4.004482e-04         100   \n",
       "40       0.001002  2.533976e-06         0.001000    4.422006e-07         100   \n",
       "41       0.001400  4.889866e-04         0.001001    8.064048e-07         100   \n",
       "\n",
       "   param_l1_ratio                            params  split0_test_score  \\\n",
       "0             0.1     {'alpha': 0, 'l1_ratio': 0.1}          -3.139328   \n",
       "1             0.5     {'alpha': 0, 'l1_ratio': 0.5}          -3.139328   \n",
       "2             0.7     {'alpha': 0, 'l1_ratio': 0.7}          -3.139328   \n",
       "3            0.95    {'alpha': 0, 'l1_ratio': 0.95}          -3.139328   \n",
       "4            0.99    {'alpha': 0, 'l1_ratio': 0.99}          -3.139328   \n",
       "5               1       {'alpha': 0, 'l1_ratio': 1}          -3.139328   \n",
       "6             0.1     {'alpha': 1, 'l1_ratio': 0.1}          -9.827475   \n",
       "7             0.5     {'alpha': 1, 'l1_ratio': 0.5}          -8.707071   \n",
       "8             0.7     {'alpha': 1, 'l1_ratio': 0.7}          -7.920870   \n",
       "9            0.95    {'alpha': 1, 'l1_ratio': 0.95}          -6.729435   \n",
       "10           0.99    {'alpha': 1, 'l1_ratio': 0.99}          -6.521344   \n",
       "11              1       {'alpha': 1, 'l1_ratio': 1}          -6.468807   \n",
       "12            0.1     {'alpha': 1, 'l1_ratio': 0.1}          -9.827475   \n",
       "13            0.5     {'alpha': 1, 'l1_ratio': 0.5}          -8.707071   \n",
       "14            0.7     {'alpha': 1, 'l1_ratio': 0.7}          -7.920870   \n",
       "15           0.95    {'alpha': 1, 'l1_ratio': 0.95}          -6.729435   \n",
       "16           0.99    {'alpha': 1, 'l1_ratio': 0.99}          -6.521344   \n",
       "17              1       {'alpha': 1, 'l1_ratio': 1}          -6.468807   \n",
       "18            0.1     {'alpha': 5, 'l1_ratio': 0.1}         -22.979265   \n",
       "19            0.5     {'alpha': 5, 'l1_ratio': 0.5}         -27.793488   \n",
       "20            0.7     {'alpha': 5, 'l1_ratio': 0.7}         -29.655510   \n",
       "21           0.95    {'alpha': 5, 'l1_ratio': 0.95}         -31.130307   \n",
       "22           0.99    {'alpha': 5, 'l1_ratio': 0.99}         -31.130307   \n",
       "23              1       {'alpha': 5, 'l1_ratio': 1}         -31.130307   \n",
       "24            0.1    {'alpha': 10, 'l1_ratio': 0.1}         -27.385346   \n",
       "25            0.5    {'alpha': 10, 'l1_ratio': 0.5}         -31.130307   \n",
       "26            0.7    {'alpha': 10, 'l1_ratio': 0.7}         -31.130307   \n",
       "27           0.95   {'alpha': 10, 'l1_ratio': 0.95}         -31.130307   \n",
       "28           0.99   {'alpha': 10, 'l1_ratio': 0.99}         -31.130307   \n",
       "29              1      {'alpha': 10, 'l1_ratio': 1}         -31.130307   \n",
       "30            0.1    {'alpha': 50, 'l1_ratio': 0.1}         -31.130307   \n",
       "31            0.5    {'alpha': 50, 'l1_ratio': 0.5}         -31.130307   \n",
       "32            0.7    {'alpha': 50, 'l1_ratio': 0.7}         -31.130307   \n",
       "33           0.95   {'alpha': 50, 'l1_ratio': 0.95}         -31.130307   \n",
       "34           0.99   {'alpha': 50, 'l1_ratio': 0.99}         -31.130307   \n",
       "35              1      {'alpha': 50, 'l1_ratio': 1}         -31.130307   \n",
       "36            0.1   {'alpha': 100, 'l1_ratio': 0.1}         -31.130307   \n",
       "37            0.5   {'alpha': 100, 'l1_ratio': 0.5}         -31.130307   \n",
       "38            0.7   {'alpha': 100, 'l1_ratio': 0.7}         -31.130307   \n",
       "39           0.95  {'alpha': 100, 'l1_ratio': 0.95}         -31.130307   \n",
       "40           0.99  {'alpha': 100, 'l1_ratio': 0.99}         -31.130307   \n",
       "41              1     {'alpha': 100, 'l1_ratio': 1}         -31.130307   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           -1.622463          -5.373837          -2.242246   \n",
       "1           -1.622463          -5.373837          -2.242246   \n",
       "2           -1.622463          -5.373837          -2.242246   \n",
       "3           -1.622463          -5.373837          -2.242246   \n",
       "4           -1.622463          -5.373837          -2.242246   \n",
       "5           -1.622463          -5.373837          -2.242246   \n",
       "6           -5.261525         -11.875347          -7.449195   \n",
       "7           -4.214228         -10.879261          -6.204545   \n",
       "8           -3.549562         -10.024877          -5.379553   \n",
       "9           -2.591285          -8.709842          -4.156317   \n",
       "10          -2.431385          -8.471086          -3.946327   \n",
       "11          -2.391483          -8.410171          -3.893566   \n",
       "12          -5.261525         -11.875347          -7.449195   \n",
       "13          -4.214228         -10.879261          -6.204545   \n",
       "14          -3.549562         -10.024877          -5.379553   \n",
       "15          -2.591285          -8.709842          -4.156317   \n",
       "16          -2.431385          -8.471086          -3.946327   \n",
       "17          -2.391483          -8.410171          -3.893566   \n",
       "18         -15.547104         -23.668249         -19.921063   \n",
       "19         -18.602269         -27.107849         -23.945227   \n",
       "20         -21.085059         -29.629478         -26.724595   \n",
       "21         -22.549433         -31.155204         -27.963447   \n",
       "22         -22.549433         -31.155204         -27.963447   \n",
       "23         -22.549433         -31.155204         -27.963447   \n",
       "24         -19.159534         -27.635464         -24.154104   \n",
       "25         -22.549433         -31.155204         -27.963447   \n",
       "26         -22.549433         -31.155204         -27.963447   \n",
       "27         -22.549433         -31.155204         -27.963447   \n",
       "28         -22.549433         -31.155204         -27.963447   \n",
       "29         -22.549433         -31.155204         -27.963447   \n",
       "30         -22.549433         -31.155204         -27.963447   \n",
       "31         -22.549433         -31.155204         -27.963447   \n",
       "32         -22.549433         -31.155204         -27.963447   \n",
       "33         -22.549433         -31.155204         -27.963447   \n",
       "34         -22.549433         -31.155204         -27.963447   \n",
       "35         -22.549433         -31.155204         -27.963447   \n",
       "36         -22.549433         -31.155204         -27.963447   \n",
       "37         -22.549433         -31.155204         -27.963447   \n",
       "38         -22.549433         -31.155204         -27.963447   \n",
       "39         -22.549433         -31.155204         -27.963447   \n",
       "40         -22.549433         -31.155204         -27.963447   \n",
       "41         -22.549433         -31.155204         -27.963447   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -4.341671        -3.343909        1.366384                1  \n",
       "1           -4.341671        -3.343909        1.366384                1  \n",
       "2           -4.341671        -3.343909        1.366384                1  \n",
       "3           -4.341671        -3.343909        1.366384                1  \n",
       "4           -4.341671        -3.343909        1.366384                1  \n",
       "5           -4.341671        -3.343909        1.366384                1  \n",
       "6           -8.542329        -8.591174        2.222939               17  \n",
       "7           -7.173031        -7.435627        2.255532               15  \n",
       "8           -6.324836        -6.639940        2.206213               13  \n",
       "9           -5.329916        -5.503359        2.102835               11  \n",
       "10          -5.151344        -5.304297        2.079945                9  \n",
       "11          -5.105922        -5.253990        2.073832                7  \n",
       "12          -8.542329        -8.591174        2.222939               17  \n",
       "13          -7.173031        -7.435627        2.255532               15  \n",
       "14          -6.324836        -6.639940        2.206213               13  \n",
       "15          -5.329916        -5.503359        2.102835               11  \n",
       "16          -5.151344        -5.304297        2.079945                9  \n",
       "17          -5.105922        -5.253990        2.073832                7  \n",
       "18         -16.262737       -19.675684        3.334901               19  \n",
       "19         -18.064635       -23.102694        4.108297               20  \n",
       "20         -20.223654       -25.463659        4.077877               22  \n",
       "21         -21.698192       -26.899317        4.077240               23  \n",
       "22         -21.698192       -26.899317        4.077240               23  \n",
       "23         -21.698192       -26.899317        4.077240               23  \n",
       "24         -18.968161       -23.460522        3.794608               21  \n",
       "25         -21.698192       -26.899317        4.077240               23  \n",
       "26         -21.698192       -26.899317        4.077240               23  \n",
       "27         -21.698192       -26.899317        4.077240               23  \n",
       "28         -21.698192       -26.899317        4.077240               23  \n",
       "29         -21.698192       -26.899317        4.077240               23  \n",
       "30         -21.698192       -26.899317        4.077240               23  \n",
       "31         -21.698192       -26.899317        4.077240               23  \n",
       "32         -21.698192       -26.899317        4.077240               23  \n",
       "33         -21.698192       -26.899317        4.077240               23  \n",
       "34         -21.698192       -26.899317        4.077240               23  \n",
       "35         -21.698192       -26.899317        4.077240               23  \n",
       "36         -21.698192       -26.899317        4.077240               23  \n",
       "37         -21.698192       -26.899317        4.077240               23  \n",
       "38         -21.698192       -26.899317        4.077240               23  \n",
       "39         -21.698192       -26.899317        4.077240               23  \n",
       "40         -21.698192       -26.899317        4.077240               23  \n",
       "41         -21.698192       -26.899317        4.077240               23  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d666a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf950ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb58aa58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.298716697886379"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c973ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
